{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Introduction to Theano</h1>\n",
    "\n",
    "<h2 align=\"center\">Jorge A. Vanegas</h2>\n",
    "\n",
    "<div align=\"center\"><img src=\"images/mindlab-logo-simple.png\" style=\"width: 160px; display: inline; padding:25px;\"> <img src=\"images/unal-logo.png\" style=\"width: 150px; display: inline; padding: 0 0 20px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "* What’s Theano?\n",
    "* Using Theano\n",
    "* Basic Usage: \n",
    "    * Building expressions\n",
    "    * Compiling and running expressions\n",
    "* Advanced Usage: \n",
    "    * Modifying expressions\n",
    "    * Debugging \n",
    "* Case study 1: Logistic Regression\n",
    "* Case study 2: Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What’s Theano?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Theano is a Python library that lets you to define, optimize, and evaluate mathematical expressions.\n",
    "* Easy to define expressions\n",
    "    * Expressions mimic NumPy's syntax and semantics\n",
    "* Possible to manipulate those expressions\n",
    "    * Substitutions\n",
    "    * Gradient\n",
    "    * Stability optimizations\n",
    "    \n",
    "## Fast to compute values for those expressions\n",
    "* Speed optimizations\n",
    "* Use fast back-ends (CUDA, BLAS, custom Ccode)\n",
    "\n",
    "## Tools to inspect and check for correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Related projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Blocks\n",
    "* Keras\n",
    "* Lasagne\n",
    "* Morb\n",
    "* Pylearn2\n",
    "* PyMC 3\n",
    "* Sklearn-theano\n",
    "* Theano-rnn\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# How to install Theano\n",
    "http://deeplearning.net/software/theano/install.html#install\n",
    "\n",
    "Requirements\n",
    "* OS: Linux, Mac OS X, Windows\n",
    "* Python: >= 2.6\n",
    "* NumPy, SciPy, BLAS \n",
    "<pre><code>\n",
    "    pip install [--upgrade] theano\n",
    "</code></pre>\n",
    "<pre><code>\n",
    "    easy_install [--upgrade] theano\n",
    "</code></pre>\n",
    "\n",
    "Install from source code\n",
    "https://github.com/Theano/Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numpy\n",
    "\n",
    "* Numpy is the core library for scientific computing in Python. \n",
    "* It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
    "\n",
    "NumPy for Matlab Users:\n",
    "\n",
    "[http://scipy.github.io/old-wiki/pages/NumPy_for_Matlab_Users.html](http://scipy.github.io/old-wiki/pages/NumPy_for_Matlab_Users.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "(3,)\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])  # Create a rank 1 array\n",
    "print a\n",
    "print a.shape\n",
    "print a[0], a[1], a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 3]\n"
     ]
    }
   ],
   "source": [
    "a[0] = 5                 # Change an element of the array\n",
    "print a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "(2, 3)\n",
      "2\n",
      "[[1 2]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1,2,3],[4,5,6]])   # Create a rank 2 array\n",
    "print b\n",
    "print b.shape\n",
    "print b[0, 1]\n",
    "print b[0:1, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Numpy provides many functions to create arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,2))  # Create an array of all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1,2))   # Create an array of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(2)        # Create a 2x2 identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83929762,  0.22563257],\n",
       "       [ 0.59273771,  0.01902199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((2,2)) # Create an array filled with random values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Array math - Elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]], dtype=np.float32)\n",
    "y = np.array([[5,6],[7,8]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.   8.]\n",
      " [ 10.  12.]]\n"
     ]
    }
   ],
   "source": [
    "print x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.   8.]\n",
      " [ 10.  12.]]\n"
     ]
    }
   ],
   "source": [
    "print np.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4. -4.]\n",
      " [-4. -4.]]\n"
     ]
    }
   ],
   "source": [
    "print x - y # np.subtract(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.  12.]\n",
      " [ 21.  32.]]\n"
     ]
    }
   ],
   "source": [
    "print x * y # np.multiply(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2         0.33333334]\n",
      " [ 0.42857143  0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "print x / y # np.divide(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.41421354]\n",
      " [ 1.73205078  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print np.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** * ** is elementwise multiplication, not matrix multiplication. We instead use the **dot** function to compute inner products of vectors, to multiply a vector by a matrix, and to multiply matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "y = np.array([[5,6],[7,8]])\n",
    "\n",
    "v = np.array([9,10])\n",
    "w = np.array([11, 12])\n",
    "\n",
    "# Inner product of vectors\n",
    "print v.dot(w)\n",
    "print np.dot(v, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix / matrix product\n",
    "print x.dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Array math - Other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[4 6]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "\n",
    "print np.sum(x)  # Compute sum of all elements; prints \"10\"\n",
    "print np.sum(x, axis=0)  # Compute sum of each column; prints \"[4 6]\"\n",
    "print np.sum(x, axis=1)  # Compute sum of each row; prints \"[3 7]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2], [3,4]])\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "print x.T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theano language\n",
    "* Operations on scalar, vector, matrix, tensor, and sparse variables\n",
    "* Linear algebra\n",
    "* Element-wise nonlinearities\n",
    "* Convolution\n",
    "* Extensible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 1. Define expression\n",
    "$$f(x, y) = x + y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 2. Compile expression\n",
    "\n",
    "    int f(int x, int y) {\n",
    "        return x + y;\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 3. Execute expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Example: Adding two Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) Define expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = T.dscalar('x')  # symbolic variables\n",
    "y = T.dscalar('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z = x + y # symbolic expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Compile expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "# first arg is list of SYMBOLIC inputs; second arg is SYMBOLIC output\n",
    "f = theano.function([x, y], z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3) Execute expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call it with NUMERICAL values; Get a NUMERICAL output\n",
    "f(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(28.4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(16.3, 12.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Theano - Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Building Symbolic Expressions\n",
    "\n",
    "**theano.tensor**\n",
    "\n",
    "Theano also has variable types for vectors, matrices, and tensors. The theano.tensor submodule has various functions for performing operations on these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = T.matrix('A')\n",
    "x = T.vector('x')\n",
    "b = T.vector('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Expressions mimic NumPy’s syntax & semantics\n",
    "\n",
    "$$ y = A∙x + b $$ \n",
    "$$ z = \\left \\| A \\right \\|_2^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y = T.dot(A, x) + b\n",
    "# Note that squaring a matrix is element-wise\n",
    "z = T.sum(A**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**theano.function**\n",
    "\n",
    "* **theano.function** can compute multiple things at a time\n",
    "* You can also set default parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 18.,  37.], dtype=float32), array(91.0, dtype=float32)]\n",
      "[array([ 14.,  32.], dtype=float32), array(91.0, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "b_default = np.array([0, 0], dtype=theano.config.floatX)\n",
    "linear_mix = theano.function([A, x, theano.Param(b, default=b_default)], [y, z])\n",
    "\n",
    "# Supplying values for A, x, and b\n",
    "print(linear_mix(np.array([[1, 2, 3],\n",
    "                           [4, 5, 6]], dtype=theano.config.floatX), #A\n",
    "                 np.array([1, 2, 3], dtype=theano.config.floatX), #x\n",
    "                 np.array([4, 5], dtype=theano.config.floatX))) #b\n",
    "\n",
    "# Using the default value for b\n",
    "print(linear_mix(np.array([[1, 2, 3],\n",
    "                           [4, 5, 6]], dtype=theano.config.floatX), #A\n",
    "                 np.array([1, 2, 3], dtype=theano.config.floatX))) #x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tensors\n",
    "* Dimensionality defined by length of “broadcastable” argument\n",
    "* Can add (or do other elemwise op) on two tensors with same dimensionality\n",
    "* Duplicate tensors along broadcastable axes to make size match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "\n",
    "tensor3 = T.TensorType(broadcastable=[False, False, False], dtype='float32')\n",
    "x = tensor3('x')\n",
    "\n",
    "matrix = T.TensorType(broadcastable=[False, False], dtype='float32')\n",
    "x = matrix('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Broadcasting Tensors\n",
    "* Implicit replication of arrays along broadcastable dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"images/bcast.png\" style=\"width: 250px;\" ></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.],\n",
       "       [ 4.,  6.],\n",
       "       [ 6.,  8.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.TensorType(broadcastable=[True, False], dtype='float32')('x')\n",
    "y = T.matrix('y')\n",
    "f = theano.function([x, y], x + y)\n",
    "\n",
    "x_value = np.array([[1, 2]], dtype=theano.config.floatX)\n",
    "\n",
    "y_value = np.array([[1, 2],\n",
    "                    [3, 4],\n",
    "                    [5, 6]], dtype=theano.config.floatX)\n",
    "                   \n",
    "f(x_value, y_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"images/bcast.png\" style=\"width: 250px;\" ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Graph structure\n",
    "\n",
    "<table style=\"border:none;\">\n",
    "<tr style=\"border:none;\">\n",
    "<td style=\"border:none;\"> \n",
    "The graph that represents mathematical operations is <b>bipartite</b>, and two sorts nodes:\n",
    "<br>\n",
    "<br>\n",
    "<lu>\n",
    "<li>\n",
    "<b>Variable</b> nodes, that represent data\n",
    "</li>\n",
    "<li>\n",
    "<b>Apply</b> nodes, that represent the application of mathematical operations\n",
    "</li>\n",
    "<li>\n",
    "<b>Op</b> nodes\n",
    "</li>\n",
    "<li>\n",
    "<b>type</b> nodes\n",
    "</li>\n",
    "</lu>\n",
    "<pre>\n",
    "<code>\n",
    "import theano.tensor as T\n",
    "\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "z = x + y\n",
    "</code>\n",
    "</pre>\n",
    "</td>\n",
    "<td style=\"border:none;\"> \n",
    "<img src=\"images/graph-structure.png\" style=\"width: 450px;\"> \n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# printing.debugprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace} [id A] ''   \n",
      " |x [id B]\n",
      " |y [id C]\n"
     ]
    }
   ],
   "source": [
    "from theano import printing\n",
    "printing.debugprint(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{true_div,no_inplace} [id A] ''   \n",
      " |w [id B]\n",
      " |Elemwise{add,no_inplace} [id C] ''   \n",
      "   |x [id D]\n",
      "   |y [id E]\n"
     ]
    }
   ],
   "source": [
    "w = T.dmatrix('w')\n",
    "printing.debugprint(w/z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# printing.pydotprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"206pt\" viewBox=\"0.00 0.00 467.00 206.00\" width=\"467pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 202)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-202 463,-202 463,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140411518606480 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140411518606480</title>\n",
       "<ellipse cx=\"229\" cy=\"-92\" fill=\"#ffaabb\" rx=\"108.31\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229\" y=\"-88.3\">Elemwise{add,no_inplace}</text>\n",
       "</g>\n",
       "<!-- 140411518606352 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140411518606352</title>\n",
       "<polygon fill=\"blue\" points=\"315.25,-36 142.75,-36 142.75,-0 315.25,-0 315.25,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229\" y=\"-14.3\">TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411518606480&#45;&gt;140411518606352 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140411518606480-&gt;140411518606352</title>\n",
       "<path d=\"M229,-73.937C229,-65.8072 229,-55.8761 229,-46.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"232.5,-46.4406 229,-36.4407 225.5,-46.4407 232.5,-46.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140411518606672 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140411518606672</title>\n",
       "<polygon fill=\"green\" points=\"220.25,-198 -0.25,-198 -0.25,-162 220.25,-162 220.25,-198\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-176.3\">name=x TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411518606672&#45;&gt;140411518606480 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140411518606672-&gt;140411518606480</title>\n",
       "<path d=\"M133.795,-161.803C152.075,-148.593 177.488,-130.227 197.461,-115.793\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"199.596,-118.568 205.651,-109.874 195.496,-112.894 199.596,-118.568\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-132.3\">0</text>\n",
       "</g>\n",
       "<!-- 140411518606544 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140411518606544</title>\n",
       "<polygon fill=\"green\" points=\"459.25,-198 238.75,-198 238.75,-162 459.25,-162 459.25,-198\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349\" y=\"-176.3\">name=y TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411518606544&#45;&gt;140411518606480 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140411518606544-&gt;140411518606480</title>\n",
       "<path d=\"M325.005,-161.803C306.572,-148.593 280.945,-130.227 260.804,-115.793\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.712,-112.854 252.545,-109.874 258.634,-118.544 262.712,-112.854\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-132.3\">1</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import printing\n",
    "from IPython.display import SVG\n",
    "image = printing.pydotprint(z, compact=False, return_image=True, format='svg')\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"368pt\" viewBox=\"0.00 0.00 567.00 368.00\" width=\"567pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 364)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-364 563,-364 563,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140411455961104 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140411455961104</title>\n",
       "<ellipse cx=\"329\" cy=\"-254\" fill=\"#ffaabb\" rx=\"108.31\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-250.3\">Elemwise{add,no_inplace}</text>\n",
       "</g>\n",
       "<!-- 140411455962960 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140411455962960</title>\n",
       "<polygon fill=\"none\" points=\"415.25,-198 242.75,-198 242.75,-162 415.25,-162 415.25,-198\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329\" y=\"-176.3\">TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411455961104&#45;&gt;140411455962960 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140411455961104-&gt;140411455962960</title>\n",
       "<path d=\"M329,-235.937C329,-227.807 329,-217.876 329,-208.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"332.5,-208.441 329,-198.441 325.5,-208.441 332.5,-208.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140411455950288 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140411455950288</title>\n",
       "<polygon fill=\"green\" points=\"320.25,-360 99.75,-360 99.75,-324 320.25,-324 320.25,-360\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-338.3\">name=x TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411455950288&#45;&gt;140411455961104 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140411455950288-&gt;140411455961104</title>\n",
       "<path d=\"M233.795,-323.803C252.075,-310.593 277.488,-292.227 297.461,-277.793\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"299.596,-280.568 305.651,-271.874 295.496,-274.894 299.596,-280.568\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-294.3\">0</text>\n",
       "</g>\n",
       "<!-- 140411455961040 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140411455961040</title>\n",
       "<polygon fill=\"green\" points=\"559.25,-360 338.75,-360 338.75,-324 559.25,-324 559.25,-360\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"449\" y=\"-338.3\">name=y TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411455961040&#45;&gt;140411455961104 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140411455961040-&gt;140411455961104</title>\n",
       "<path d=\"M425.005,-323.803C406.572,-310.593 380.945,-292.227 360.804,-277.793\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"362.712,-274.854 352.545,-271.874 358.634,-280.544 362.712,-274.854\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402.5\" y=\"-294.3\">1</text>\n",
       "</g>\n",
       "<!-- 140411455963024 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140411455963024</title>\n",
       "<ellipse cx=\"173\" cy=\"-92\" fill=\"#ffaabb\" rx=\"124.184\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-88.3\">Elemwise{true_div,no_inplace}</text>\n",
       "</g>\n",
       "<!-- 140411455962960&#45;&gt;140411455963024 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140411455962960-&gt;140411455963024</title>\n",
       "<path d=\"M297.806,-161.803C273.149,-148.211 238.59,-129.159 212.088,-114.549\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.527,-111.345 203.08,-109.582 210.147,-117.475 213.527,-111.345\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267.5\" y=\"-132.3\">1</text>\n",
       "</g>\n",
       "<!-- 140411455961808 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140411455961808</title>\n",
       "<polygon fill=\"blue\" points=\"259.25,-36 86.75,-36 86.75,-0 259.25,-0 259.25,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-14.3\">TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411455963024&#45;&gt;140411455961808 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140411455963024-&gt;140411455961808</title>\n",
       "<path d=\"M173,-73.937C173,-65.8072 173,-55.8761 173,-46.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"176.5,-46.4406 173,-36.4407 169.5,-46.4407 176.5,-46.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140411455950032 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140411455950032</title>\n",
       "<polygon fill=\"green\" points=\"223.5,-198 0.5,-198 0.5,-162 223.5,-162 223.5,-198\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112\" y=\"-176.3\">name=w TensorType(float64, matrix)</text>\n",
       "</g>\n",
       "<!-- 140411455950032&#45;&gt;140411455963024 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140411455950032-&gt;140411455963024</title>\n",
       "<path d=\"M124.344,-161.597C133.166,-149.159 145.174,-132.23 155.054,-118.302\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"157.952,-120.265 160.882,-110.084 152.242,-116.216 157.952,-120.265\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151.5\" y=\"-132.3\">0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = printing.pydotprint(w/z, compact=False, return_image=True, format='svg')\n",
    "SVG(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimizations\n",
    "Theano changes the symbolic expressions you write before converting them to C code\n",
    "* It makes them faster\n",
    "\n",
    "$$(x+y) + (x+y) \\rightarrow 2 * (x+y)$$\n",
    "\n",
    "* It makes them more stable\n",
    "\n",
    "$$exp(a) / exp(a).sum(axis=1) \\rightarrow softmax(a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimizations\n",
    "* Sometimes optimizations discard error checking and produce incorrect output rather than an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.0, dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.scalar()\n",
    "f = theano.function([x], x/x)\n",
    "f(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Theano - Advanced Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Shared variables\n",
    "* A **shared variable** is a buffer that stores a numerical value for a theano variable\n",
    "     * think as a global variable\n",
    "* Modify outside function with **get_value** and **set_value**\n",
    "* They're also useful because they have state across function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CudaNdarrayType(float32, matrix)>\n"
     ]
    }
   ],
   "source": [
    "shared_var = theano.shared(np.array([[1, 2], [3, 4]], dtype=theano.config.floatX))\n",
    "# The type of the shared variable is deduced from its initialization\n",
    "print(shared_var.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  4.]\n",
      " [ 2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# We can set the value of a shared variable using set_value\n",
    "shared_var.set_value(np.array([[3, 4], [2, 1]], dtype=theano.config.floatX))\n",
    "# ..and get it using get_value\n",
    "print(shared_var.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.  16.]\n",
      " [  4.   1.]]\n"
     ]
    }
   ],
   "source": [
    "shared_squared = shared_var**2\n",
    "# Note that because shared_var is shared, it already has a value, so it doesn't need to be an input to the function.\n",
    "function_1 = theano.function([], shared_squared)\n",
    "print(function_1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  The updates keyword\n",
    "* We can also update the state of a shared variable in a function\n",
    "* Updates takes a dict where keys are shared variables and values are the new value the shared variable should take\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_var before using function_2:\n",
      "[[ 3.  4.]\n",
      " [ 2.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"shared_var before using function_2:\")\n",
    "print(shared_var.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_var after calling function_2:\n",
      "[[ 2.  3.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "subtract = T.matrix('subtract')\n",
    "# Here, updates will set shared_var = shared_var - subtract\n",
    "function_2 = theano.function([subtract], [], updates={shared_var: shared_var - subtract})\n",
    "# Subtract [[1, 1], [1, 1]] from shared_var\n",
    "function_2(np.array([[1, 1], [1, 1]], dtype=theano.config.floatX))\n",
    "print(\"shared_var after calling function_2:\")\n",
    "print(shared_var.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  9.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# This also changes the output of function_1, because shared_var is shared!\n",
    "print(function_1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Manipulating Symbolic Expressions\n",
    "# Graph Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#Automatic differentiation\n",
    "* **tensor.grad(func, [params])**\n",
    "* The second argument of **grad()** can be a list (partial derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x ** TensorConstant{2})'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dscalar('x')\n",
    "y = x**2\n",
    "theano.pp(y) # print out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill((x ** TensorConstant{2}), TensorConstant{1.0}) * TensorConstant{2}) * (x ** (TensorConstant{2} - TensorConstant{1})))'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gy = T.grad(y, x)\n",
    "theano.pp(gy) # print out the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(16.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = theano.function([x], y)\n",
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf = theano.function([x], gy)\n",
    "gf(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Substitution\n",
    "\n",
    "##The **givens** keyword\n",
    "\n",
    "* Substitution at the moment, when compiling a function\n",
    "\n",
    "* The **givens** parameter allow you to separate the description of the model and the exact definition of the inputs variable.\n",
    "\n",
    "* The **givens** parameter can be used to replace any symbolic variable, not just a shared variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  43.,   92.,  135.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original model\n",
    "\n",
    "A = theano.shared(np.array([[1, 2, 4], [5, 6, 7], [8, 9, 10]], dtype=theano.config.floatX))\n",
    "b = theano.shared(np.array([[1, 2, 3]], dtype=theano.config.floatX))\n",
    "x = T.vector('x')\n",
    "\n",
    "y = T.dot(A, x) + b\n",
    "f = theano.function([x], y)\n",
    "\n",
    "input_data = np.array([2, 4, 8], dtype=theano.config.floatX)\n",
    "f(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "we want to add a preprocessing step\n",
    "\n",
    "    x_n = (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.74165773,  4.40535164,  5.40535355]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefine the model?\n",
    "x_n = (x - x.mean()) / x.std()\n",
    "y = T.dot(A, x_n) + b\n",
    "\n",
    "f = theano.function([x], y)\n",
    "f(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.74165773,  4.40535164,  5.40535355]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a preprocessing function?\n",
    "x0 = T.vector('x')\n",
    "x_n = (x0 - x0.mean()) / x0.std()\n",
    "f_n = theano.function([x0], x_n)\n",
    "\n",
    "# original model\n",
    "y = T.dot(A, x) + b\n",
    "f = theano.function([x], y)\n",
    "\n",
    "preprocessing_data = f_n(input_data)\n",
    "f(preprocessing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.74165773,  4.40535164,  5.40535355]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using givens\n",
    "# preprocessing definition\n",
    "x0 = T.vector('x')\n",
    "x_n = (x0 - x0.mean()) / x0.std()\n",
    "\n",
    "# original model\n",
    "y = T.dot(A, x) + b\n",
    "\n",
    "f_n = theano.function([x0], y, givens={x: x_n})\n",
    "f_n(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Debugging\n",
    "\n",
    "* DebugMode\n",
    "* compute_test_value\n",
    "* min_informative_str\n",
    "* DebugPrint\n",
    "* Accessing the FunctionGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DebugMode\n",
    "* The DebugMode is designed to run several self-checks and assertions that can help diagnose possible programming errors leading to incorrect output\n",
    "* It is recommended you use **DebugMode** during development\n",
    "\n",
    "Preset compilation mode:\n",
    "* FAST_RUN\n",
    "* FAST_COMPILE\n",
    "* DEBUG_MODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Without DebugMode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(inf)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor\n",
    "\n",
    "x = tensor.dscalar('x')\n",
    "f = theano.function([x], 10/x)\n",
    "f(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* DebugMode can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "InvalidValueError",
     "evalue": "InvalidValueError\n        type(variable) = TensorType(float64, scalar)\n        variable       = Elemwise{true_div,no_inplace}.0\n        type(value)    = <type 'numpy.ndarray'>\n        dtype(value)   = float64\n        shape(value)   = ()\n        value          = inf\n        min(value)     = inf\n        max(value)     = inf\n        isfinite       = False\n        client_node    = None\n        hint           = perform output\n        specific_hint  = non-finite elements not allowed\n        context        = ...\n  Elemwise{true_div,no_inplace} [id A] ''   \n   |TensorConstant{10} [id B]\n   |x [id C]\n\n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-e8968f34093b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DebugMode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/debugmode.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2339\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_isfinite\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2340\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2341\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2342\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2343\u001b[0m                     \u001b[1;31m# put back the filter_checks_isfinite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/debugmode.pyc\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2079\u001b[0m                                 raise InvalidValueError(r, storage_map[r][0],\n\u001b[0;32m   2080\u001b[0m                                                         \u001b[0mhint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'perform output'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m                                                         specific_hint=hint2)\n\u001b[0m\u001b[0;32m   2082\u001b[0m                         \u001b[0mwarn_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDebugMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_input_not_reused\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m                         py_inplace_outs = _check_inputs(\n",
      "\u001b[1;31mInvalidValueError\u001b[0m: InvalidValueError\n        type(variable) = TensorType(float64, scalar)\n        variable       = Elemwise{true_div,no_inplace}.0\n        type(value)    = <type 'numpy.ndarray'>\n        dtype(value)   = float64\n        shape(value)   = ()\n        value          = inf\n        min(value)     = inf\n        max(value)     = inf\n        isfinite       = False\n        client_node    = None\n        hint           = perform output\n        specific_hint  = non-finite elements not allowed\n        context        = ...\n  Elemwise{true_div,no_inplace} [id A] ''   \n   |TensorConstant{10} [id B]\n   |x [id C]\n\n        "
     ]
    }
   ],
   "source": [
    "f = theano.function([x], 10/x, mode='DebugMode')\n",
    "f(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DebugMode\n",
    "* **DebugMode** will raise an exception according to what went wrong, either at call time <code>(f(0))</code> or compile time (<code>f = theano.function(x, 10*x, mode='DebugMode')</code>). \n",
    "* It can also be used by setting the configuration variable config.mode. \n",
    "* It can also be used by passing a DebugMode instance as the mode, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from theano.compile.debugmode import DebugMode\n",
    "\n",
    "f = theano.function([x], 10*x, mode=DebugMode(check_c_code=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Validation options:\n",
    "* stability_patience\n",
    "* check_c_code\n",
    "* check_py_code\n",
    "* check_isfinite\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# compute_test_value\n",
    "Theano has a  mechanism by which graphs are executed on-the-fly, before a theano.function is ever compiled. Since optimizations haven’t been applied at this stage, it is easier for the user to locate the source of some bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# compute_test_value = 'off'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 3, but the output's size on that axis is 2.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0)\nToposort index: 2\nInputs types: [CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector)]\nInputs shapes: [(2,), (3,)]\nInputs strides: [(1,), (1,)]\nInputs values: [<CudaNdarray object at 0x7fb413339d30>, <CudaNdarray object at 0x7fb413319a70>]\nOutputs clients: [[HostFromGpu(GpuElemwise{Add}[(0, 0)].0)]]\n\nDebugprint of the apply node: \nGpuElemwise{Add}[(0, 0)] [id A] <CudaNdarrayType(float32, vector)> ''   \n |GpuFromHost [id B] <CudaNdarrayType(float32, vector)> ''   \n | |<TensorType(float32, vector)> [id C] <TensorType(float32, vector)>\n |GpuFromHost [id D] <CudaNdarrayType(float32, vector)> ''   \n   |<TensorType(float32, vector)> [id E] <TensorType(float32, vector)>\n\nStorage map footprint:\n - <TensorType(float32, vector)>, Input, Shape: (3,), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - GpuFromHost.0, Shape: (3,), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - GpuFromHost.0, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - <TensorType(float32, vector)>, Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n TotalSize: 40 Byte(s) 0.000 GB\n TotalSize inputs: 20 Byte(s) 0.000 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-e09c172b1e8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0my_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 3, but the output's size on that axis is 2.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuFromHost.0, GpuFromHost.0)\nToposort index: 2\nInputs types: [CudaNdarrayType(float32, vector), CudaNdarrayType(float32, vector)]\nInputs shapes: [(2,), (3,)]\nInputs strides: [(1,), (1,)]\nInputs values: [<CudaNdarray object at 0x7fb413339d30>, <CudaNdarray object at 0x7fb413319a70>]\nOutputs clients: [[HostFromGpu(GpuElemwise{Add}[(0, 0)].0)]]\n\nDebugprint of the apply node: \nGpuElemwise{Add}[(0, 0)] [id A] <CudaNdarrayType(float32, vector)> ''   \n |GpuFromHost [id B] <CudaNdarrayType(float32, vector)> ''   \n | |<TensorType(float32, vector)> [id C] <TensorType(float32, vector)>\n |GpuFromHost [id D] <CudaNdarrayType(float32, vector)> ''   \n   |<TensorType(float32, vector)> [id E] <TensorType(float32, vector)>\n\nStorage map footprint:\n - <TensorType(float32, vector)>, Input, Shape: (3,), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - GpuFromHost.0, Shape: (3,), ElemSize: 4 Byte(s), TotalSize: 12 Byte(s)\n - GpuFromHost.0, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - <TensorType(float32, vector)>, Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n TotalSize: 40 Byte(s) 0.000 GB\n TotalSize inputs: 20 Byte(s) 0.000 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "# compute_test_value is 'off' by default, meaning this feature is inactive\n",
    "theano.config.compute_test_value = 'off' # Use 'warn' to activate this feature\n",
    "\n",
    "x = T.vector()\n",
    "y = T.vector()\n",
    "z = x + y\n",
    "\n",
    "f = theano.function([x, y], z, allow_input_downcast=True)\n",
    "\n",
    "x_value = np.ones((2,))\n",
    "y_value = np.ones((3,))\n",
    "\n",
    "f(x_value, y_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# compute_test_value = 'warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[0] = 2, input[1].shape[0] = 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8f093db99a81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;31m# We should catch the minimum number of exception here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Otherwise this will convert error when Theano flags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                 \u001b[0mrequired\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[1;31m# We provided all inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m()\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mfill_storage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1712\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[0] = 2, input[1].shape[0] = 3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "# enable on-the-fly graph computations\n",
    "theano.config.compute_test_value = 'warn'\n",
    "\n",
    "x = T.vector()\n",
    "x.tag.test_value = np.ones((2,)).astype(theano.config.floatX)\n",
    "y = T.vector()\n",
    "y.tag.test_value = np.ones((3,)).astype(theano.config.floatX)\n",
    "\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# not compute test values\n",
    "theano.config.compute_test_value = 'off'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# min_informative_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A. Elemwise{mul,no_inplace}\n",
      " B. TensorConstant{2.0}\n",
      " C. z\n"
     ]
    }
   ],
   "source": [
    "from theano.printing import min_informative_str\n",
    "\n",
    "x = T.scalar()\n",
    "y = T.scalar()\n",
    "z = x + y\n",
    "z.name = 'z'\n",
    "a = 2. * z\n",
    "\n",
    "print min_informative_str(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# debugprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{mul,no_inplace} [id A] ''   \n",
      " |TensorConstant{2.0} [id B]\n",
      " |Elemwise{add,no_inplace} [id C] 'z'   \n",
      "   |<TensorType(float32, scalar)> [id D]\n",
      "   |<TensorType(float32, scalar)> [id E]\n"
     ]
    }
   ],
   "source": [
    "from theano.printing import debugprint\n",
    "\n",
    "debugprint(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Accessing the FunctionGraph ($fgraph$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCopyOp [id A] ''   \n",
      " |TensorConstant{2.0} [id B]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "\n",
    "x = T.scalar()\n",
    "y = 2 * x / x\n",
    "f = theano.function([x], y)\n",
    "debugprint(f.maker.fgraph.outputs[0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
